---
title: "Dealing with different identifications of the same animal"
output: html_notebook
---
##Introduction
Because we host our project on the zooniverse, it is possible to have multiple people score each event, which means we may not get the same answers for each event in terms of species id, behavior, etc.

To that end, we need a way to check which events have differences in their identifications of species and of e.g. behaviors.  Once those events are identified, we need an efficient way to go back to those events and make a final appraisal of their contents.

The following bunch of R scripts takes the flattened classfication file produced by running the *Flatten-zooniverse-NoCoWild.Rmd* scripts and does the following:  

1. Identify which events have more than one classification
2. For those events with more than 1 classification, determine which ones have more than one species identified.
3. For those events with more than 1 species identified, determine which species will be assigned to the event. (An alternative, less good temporary step is to simply take the first classification for each event for which there are duplicate classifications)

##Prep the workspace

```{r}
#set up workspace
rm(list = ls())
library(dplyr)
library(ggplot2)
library(magrittr)
library(stringr)
library(tidyr)
```
Pull in the data file
```{r}
classification_file<-"sampledatasmall.csv-flattened.csv"
library(readr)
DF<- read_csv(classification_file)
```

Source TEAM library scripts
```{r}
source("/Volumes/External Drive/Dropbox/R/NoCoWild/CamTrapAnalysis/Camera Trapping for Wildlife Research/Chapter 5/TEAM Library 1.7.R")
```
Summarize the data and create a new column that has a count of how many unique identifications, and tallies how many people identified each new photo.
```{r}
DF %>% summarise(n_distinct(subject_ids), n_distinct(classification_id)) 
```
With this example file, there are 218 distinct subject ids and 249 distinct classifications.  The difference $$248-218 = 31$$ should be subjects that were classified more than once.

```{r}
New<- DF %>% 
     group_by(subject_ids) %>% # count up the number of distinct classification IDs
     mutate(., num_class = n_distinct(classification_id)) %>% #because there will be >1 row per classification_id if >1 spp
     arrange(., subject_ids, classification_id) 

New %>% View
```
Now in the New data frame we can see the column `num_class` identifies the number of times each subject id was classified. 

##Clean up multiple votes per user
Now that we've identified which subject ids have more than one classification we should clean them up so that we can have a single species classification for each event.

Code from the Zooniverse 
```{r}
check_spp_counts <- New %>% 
     group_by(subject_ids, classification_id) %>% 
     mutate(., num_species = n_distinct(choice), check_num_spp = n())
```
Quickly, this shows us how many distinct species were assigned and then checks the number of species.

Let's just look at the repeats to see if the code seems to work:

```{r}
Repeats<-check_spp_counts %>% group_by(subject_ids) %>% filter(n()>1)
Repeats

#gives those subject ids that appear more than once
```
In this particular case, none of the events were classified as more than a single species, so we just need to remove the repeated case of each event from the df for further processing.

If we had seen that some events were classified as different species, go below to the section called XXXXXXXXX to see what to do.

##Check for duplicates
Now we check for duplicates
Need to use function Zooniverse people created
```{r}
check_dups <- function(New) {
     # This function groups by subject and classification ID (which is per user/classification), 
     # then checks whether the number of unique species == the number of submissions. 
     # So, if a person selects lion & zebra, num_species and check_num_species will both = 2. 
     # If a person selects lion, 1, standing and lion, 1, sitting, then num_species = 1 and check_num_species = 2.
     # Note that this error will not be possible in future projects.
     # Also note that we can't actually combine answers in a generalized way, 
     # because "how many" is actually categorical and the values differ for all projects.
     bad_counts <- New %>% 
          group_by(subject_ids, classification_id) %>% 
          mutate(., num_species = n_distinct(choice), check_num_spp = n()) %>%
          filter(., num_species != check_num_spp) 
     check <- bad_counts %>% nrow() %>% as.numeric()
     
     if(check > 0) {
          print("You've got duplicates, dammit")
          return(bad_counts)
     } else if(check == 0) {
          print("You've got no duplicates! Well done!")
     }
}

```
Now run the function
```{r}
bad_counts<- check_dups(check_spp_counts)
```
We can just run the next code chunk - creates `cleaned_classifications` as the correct dataset, dropping duplicates where necessary
```{r}
if(is.null(dim(bad_counts))) {
     print("No duplicates to drop")
     cleaned_classifications <- check_spp_counts
} else {
     # NOTE that I don't know how you combine different answers for a single choice questions, thus, this just takes the FIRST anser
     print(paste("Dropping", dim(check_dups(raw_data))[1], "duplicate classifications"))
     
     cleaned_classifications <- raw_data %>% group_by(subject_ids, classification_id) %>% 
          mutate(., num_species = n_distinct(choice)) %>%
          group_by(., subject_ids, classification_id, num_class, num_species, choice) %>% 
          #summarise_all(., sum) # adds up counts for duplicates of spp, only works if everything is numeric
          summarise_all(., first) # takes the first record per user per species classification
}



check_dups(cleaned_classifications)

```
At this point though, our list of 249 observations still includes the repeated rows.  We need to reduce the data set so that there is just a single classification per event so as to avoid extra couning of events.




